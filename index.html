<html>

<head>
    <title>Subhankar Mishra | CS460 Machine Learning 2024</title>
    <link href="https://www.niser.ac.in/~smishra/css/smlab.css" rel="stylesheet" type="text/css" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="apple-touch-icon" sizes="180x180"
        href="https://www.niser.ac.in/~smishra/favicon_io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32"
        href="https://www.niser.ac.in/~smishra/favicon_io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16"
        href="https://www.niser.ac.in/~smishra/favicon_io/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">

</head>

<body>
    <div class="container">
        <header>
            <h1>SUBHANKAR MISHRA</h1>
            <h2>ଶୁଭଙ୍କର ମିଶ୍ର</h2>
        </header>
        <p>
            Reader-F, School of Computer Sciences, NISER <br>
            ପାଠକ-ଏଫ, ସଂଗଣକ ବିଜ୍ଞାନ ବିଦ୍ୟାଳୟ, ନାଇଜର <br>
        </p>
        <hr /> <br>
        <div class="item">
            <h2>CS460/660 - Machine Learning 2024 (2023-24 Even Semester)</h2>
        </div>
        <h3>Teaching Assistants</h3>
        <ul>
            <li>(Lead TA) <a href="https://ruchajoshi.github.io">Rucha Bhalchandra Joshi</a> (PhD, CS)</li>
            <li> <a href="https://aniket-nath.github.io">Aniket Nath</a> (MSc, SPS)</li>
            <li> <a href="https://peithonking.github.io/portfolio-page/">Aritra Mukhopadhyay</a> (MSc, SPS)</li>
            <li>Diptarko Choudhury (MSc, SPS)</li>
            <li>Sagar Prakash Barad (MSc, SPS)</li>
            
        </ul>
        <h3>Syllabus</h3>
        <ul>
            <li>Learning, Inductive Bias, Features, Labels, Basics of Statistics and Probability</li>
            <li>Supervised Learning - Some models</li>
            <li>Ensemble Methods: Bagging, Boosting. Learning Theory</li>
            <li>Unsupervised Learning - Some models</li>
            <li>Reinforcement Learning Basics (if time permits)</li>
        </ul>

        <h3>Expected skills (No mandatory prerequisite)</h3>
        <ul>
            <li>Algorithms (CS301 or equivalent)</li>
            <li>Python</li>
            <li>Probability and Statistics</li>
        </ul>
        <h3>Grading scheme </h3>
        Grading will be absolute.
        <ul>
            <li>Project - 40 marks</li>
            <li>Assignment - 10 marks</li>
            <li>Midterm - 10 marks</li>
            <li>Endterm - 40 marks</li>
            <li>Total -100 marks</li>
        </ul>
        <h3>Lectures</h3>

        <table>
            <thead>
                <tr>
                    <th>Week</th>
                    <th>Lec #</th>
                    <th>Topic</th>
                    <th>Slide</th>
                </tr>
            </thead>
            <tbody>
                <!-- <tr>
                    <td rowspan="4">Week 1</td>
                    <td>1</td>
                    <td>Course Logistics and Introduction</td>
                    <td></td>
                </tr>
                <tr>
                    <td>2</td>
                    <td>Generalization</td>
                    <td rowspan="3"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec1.pdf">Group1</a>
                    </td>
                </tr>
                <tr>
                    <td>3</td>
                    <td>Why and when Machine Learning, </td>
                </tr>
                <tr>
                    <td>4</td>
                    <td>Inductive Learning, Structured Data </td>
                </tr>
                <tr>
                    <td rowspan="4">Week 2</td>
                    <td>5</td>
                    <td>Decision Trees</td>
                    <td rowspan="2"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec2.pdf">Group2</a>
                    </td>
                </tr>
                <tr>
                    <td>6</td>
                    <td>Inductive Bias</td>
                </tr>
                <tr>
                    <td>7</td>
                    <td>Expected Loss, Inductive vs Transductive learning</td>
                    <td rowspan="2"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec3.pdf">Group3</a>
                    </td>
                </tr>
                <tr>
                    <td>8</td>
                    <td>General approach for Machine Learning </td>
                </tr>
                <tr>
                    <td rowspan="4">Week 3</td>
                    <td>9</td>
                    <td>Types of Machine Learning (Based on Input and Output) </td>
                    <td><a href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec4.pdf">Group4</a></td>
                </tr>
                <tr>
                    <td>10</td>
                    <td>Supervised Learning - Linear SVM</td>
                    <td rowspan="2"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec5.pdf">Group5</a>
                    </td>
                </tr>
                <tr>
                    <td>11</td>
                    <td>Supervised Learning - Linear SVM (Continued)</td>
                </tr>
                <tr>
                    <td>12</td>
                    <td>Linear Regression</td>
                    <td rowspan="2"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec6.pdf">Group6</a>
                    </td>
                </tr>
                <tr>
                    <td rowspan="4">Week 4</td>
                    <td>13</td>
                    <td>Linear Regression (Continued)</td>
                    <td></td>
                </tr>
                <tr>
                    <td>14</td>
                    <td>Gradient Descent</td>
                    <td rowspan="2"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec7.pdf">Group7</a>
                    </td>
                </tr>
                <tr>
                    <td>15</td>
                    <td>Gradient Descent (Continued)</td>
                </tr>
                <tr>
                    <td>16</td>
                    <td>Logistic Regression</td>
                    <td><a href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec8.pdf">Group8</a></td>
                </tr> -->
                <tr>
                    <td rowspan="1">Week 5 (Jan 30 - Feb 2)</td>
                    <td></td>
                    <td>Project Proposal Presentations</td>
                    <td></td>
                </tr>
                <!-- <tr>
                    <td rowspan="5">Week 6</td>
                    <td>-</td>
                    <td>Quiz - 1 </td>
                    <td></td>
                </tr>
                <tr>
                    <td>17</td>
                    <td>Decision Trees - CART </td>
                    <td rowspan="2"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec9.pdf">Group9</a>
                    </td>
                </tr>
                <tr>
                    <td>18</td>
                    <td>Decision Trees - CART - Continued</td>

                </tr>
                <tr>
                    <td>-</td>
                    <td>Decision Trees - ID3</td>
                    <td><a href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec10.pdf">Group10</a>
                    </td>
                </tr>
                <tr>
                    <td>19</td>
                    <td>SVM - Hinge Loss</td>
                    <td><a href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec11.pdf">Group11</a>
                    </td>
                </tr>
                <tr>
                    <td rowspan="4">Week 7</td>
                    <td>20</td>
                    <td>SVM - Kernel Functions <a
                            href="https://see.stanford.edu/materials/aimlcs229/cs229-notes3.pdf">CS229 Notes - Andrew
                            Ng</a></td>
                    <td rowspan="2"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec12.pdf">Group12</a>
                    </td>
                </tr>
                <tr>
                    <td>21</td>
                    <td>SVM - Kernel Functions - Continued</td>
                </tr>
                <tr>
                    <td>22</td>
                    <td>kNN</td>
                    <td rowspan="2"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec13.pdf">Group13</a>
                    </td>
                </tr>
                <tr>
                    <td>-</td>
                    <td>kNN Implementation</td>
                    <td></td>
                </tr>
                <tr>
                    <td rowspan="4">Week 8</td>
                    <td>23</td>
                    <td>Feature Engineering (One-hot encoding, bucketing, normalization, standardisation, missing
                        features, imbalanced dataset) </td>
                    <td><a href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec14.pdf">Group14</a>
                    </td>
                </tr>
                <tr>
                    <td>24</td>
                    <td>Model Performance Assessment</td>
                    <td rowspan="2"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec15.pdf">Group15</a>
                    </td>
                </tr>
                <tr>
                    <td>25</td>
                    <td>Hyperparameter Tuning</td>
                </tr>
                <tr>
                    <td>-</td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td rowspan="3">Week 9</td>
                    <td>26</td>
                    <td>Unsupervised Learning - Clustering - kMeans</td>
                    <td rowspan="3"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec16.pdf">Group16</a>
                    </td>
                </tr>
                <tr>
                    <td>27</td>
                    <td>Unsupervised Learning - Clustering - DBSCAN</td>
                    </td>
                </tr>
                <tr>
                    <td>28</td>

                    <td>Unsupervised Learning - How to find the number of clusters?</td>

                </tr> -->
                <tr>
                    <td rowspan="1">Week 8 (Feb 19 - Feb 23)</td>
                    <td></td>
                    <td>Midterm Exam</td>
                    <td></td>
                </tr>
                <tr>
                    <td rowspan="1">Week 9 (Feb 26 - Mar 1)</td>
                    <td></td>
                    <td>Midsemester Break</td>
                    <td></td>
                </tr>
                <tr>
                    <td rowspan="1">Week 10,11 (Mar 4 - Mar 15)</td>
                    <td></td>
                    <td>Project Midterm Presentations</td>
                    <td></td>
                </tr>
                <!-- <tr>
                    <td rowspan="4">Week 12</td>
                    <td>29</td>
                    <td>Unsupervised Learning - Dimensionality reduction PCA</td>
                    <td rowspan="2"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec17.pdf">Group17</a>
                    </td>
                </tr>
                <tr>
                    <td>30</td>
                    <td>Unsupervised Learning - Dimensionality reduction tSNE</td>
                    </td>
                </tr>
                <tr>
                    <td>31</td>
                    <td>Bias and Variance</td>
                    <td rowspan="2"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec18.pdf">Group18</a>
                    </td>
                </tr>
                <tr>
                    <td>32</td>
                    <td>Regularization</td>
                    </td>
                </tr>
                <tr>
                    <td rowspan="4">Week 13</td>
                    <td>33</td>
                    <td>One-class classification and Multiclass classification</td>
                    <td rowspan="2"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec19.pdf">Group19</a>
                    </td>
                </tr>
                <tr>
                    <td>34</td>
                    <td>Multilabel classification</td>
                    </td>
                </tr>
                <tr>
                    <td>35</td>
                    <td>Ensemble Learning - Bagging</td>
                    <td rowspan="2"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec20.pdf">Group20</a>
                    </td>
                </tr>
                <tr>
                    <td>36</td>
                    <td>Ensemble Learning - Boosting</td>
                    </td>
                </tr>
                <tr>
                    <td rowspan="4">Week 14</td>
                    <td>37</td>
                    <td>XGBoost</td>
                    <td rowspan="2"><a
                            href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec21.pdf">Group21</a>
                    </td>
                </tr>
                <tr>
                    <td>38</td>
                    <td>AdaBoost</td>
                    </td>
                </tr>
                <tr>
                    <td>39</td>
                    <td>Naive Bayes Classifier</td>
                    <td><a href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec22.pdf">Group22</a>
                    </td>
                </tr>
                <tr>
                    <td>40</td>
                    <td>Cross Entropy Loss</td>
                    <td><a href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/lectures/lec23.pdf">Group23</a>
                    </td>
                </tr> -->
                <tr>
                    <td rowspan="1">Week 15,16 (Apr 08 - Apr 19)</td>
                    <td></td>
                    <td>Project Final Presentations</td>
                    <td></td>
                </tr>

            </tbody>
        </table>
        <hr />
        <h3>Assignments</h3>
        <ul>
            <li>[10] Poster Presentation </li>
            <ul>
                <li>Cover a topic/algorithm covered in class or related. Finalise after discussion with associated TA and instructor</li>
                <li>Sample codes as required should be shared publicly over github or otherwise</li>
                <li>Follow the github clone and pull request to update your slides, posters will be made public</li>
                <li>Upload both .pdf as well as .zip containing the source for your poster.</li>
            </ul>
            <li>[05] </li>
        </ul>
        <hr />
        <!--         
        <h3>Project</h3>
        <hr /> -->
        <h3>Project</h3>
        A group of 2. Class project must be something new that you did in this semester. Two types of projects are
        allowed:
        <ul>
            <li> Category - 1: You pick/create an interesting (new) dataset, apply best suited one or more well known
                machine
                learning algorithms as baselines and extend these baselines in your creative and interesting way. </li>
            <li> Category - 2: A theoretical project should look at an open question, definite it concretely, look at
                the literature, design and develop creative and interesting attempts.</li>
        </ul>
        Deliverables for reports will be in LaTeX generated pdf. Format should follow <a
            href="https://neurips.cc/Conferences/2022/PaperInformation/StyleFiles">NeurIPS template</a> with a plagiarism report. Codes and dataset must be shared over github/gitlab private repo.


        <ol>
            <li>[05] (Max. 2 slides) Project Proposal - 5 mins</li>
            <ul>
                <li>Title, dataset, idea, relevant papers, teammate with work division, what to do by Midway, what
                    baselines to implement, what are the expected results</li>
            </ul>
            <li>[10] (Max. 5 slides) Project Midway - 10 mins + 5 mins Q&A, Midterm Report - Max Limit 4 pages</li>
            <ul>
                <li>Insightful analysis of 2-3 related papers.</li>
                <li>Experiments you have done along with results.</li>
            </ul>
            <li>[25] (Max. 10 slides) Final Project Presentation -<s> 20 mins + 10 mins</s> 10 mins, Endterm Report -
                Max Limit 8 pages</li>
            <ul>
                <li>Review</li>
                <li>New and interesting attempts to solve the problem</li>
                <li>Plan for further work for submission</li>
            </ul>
            <li>[Extra 10] Paper Submission
                <ul>
                    <li>[5] Average conference</li> OR
                    <li>[10] Top conference - <a
                            href="https://aideadlin.es/?sub=ML,CV,CG,NLP,RO,SP,DM,AP,KR">Deadlines</a></li>
                </ul>
                Conference/Journal list: The final selection of the conference will be in coordination with the
                instructor.
        </ol>
        Submission guidelines:
        <ul>
            <li>Clone <a href="https://github.com/smlab-niser/24cs460">GitHub</a></li>
            <li>index.html</li>
            <ul>
                <li>If this is the first time, create a new row in the table, add your members, project title and
                    initialize the groups slides and reports.</li>
                <li>You will add/update the links associated with your group.</li>
            </ul>
            <li>Projects folder</li>
            <ul>
                <li>If this is the first time, create a new folder under projects folder</li>
                <li>Add/update your files in that folder only. Do not make any changes other than your group/individual
                    folder</li>
            </ul>
            <li>Create a pull request after the changes are done</li>
        </ul>
        <table>
            <thead>
                <tr>
                    <th>#</th>
                    <th>Team Members</th>
                    <th>Title</th>
                    <th>Proposal</th>
                    <th>Midterm</th>
                    <th>Final</th>
                    <th>Paper</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td rowspan="2">3</td>
                    <td>Name 1</td>
                    <td rowspan="2">Title 1</td>
                    <td rowspan="1"><a href="#">Slide</a></td>
                    <td rowspan="1"><a href="#">Slide</a></td>
                    <td rowspan="1"><a href="#">Slide</a></td>
                    <td rowspan="1"><a href="#">Slide</a></td>
                </tr>
                <tr>
                    <td>Name 2</td>
                    <td rowspan="1">---</td>
                    <td rowspan="1"><a href="#">Report</a></td>
                    <td rowspan="1"><a href="#">Report</a></td>
                    <td rowspan="1"><a href="#">Report</a></td>
                </tr>
            </tbody>

        </table>
        <hr />
        <h3>Books</h3>
        Some recommended books on Machine learning.
        <ul>
            <li>The Elements of Statistical Learning <a href="https://web.stanford.edu/~hastie/ElemStatLearn/">Link</a>
            </li>
            <li>Mathematics for Machine Learning <a href="https://mml-book.github.io">Link</a></li>
            <li>Introduction to Machine Learning with Python <a
                    href="https://www.oreilly.com/library/view/introduction-to-machine/9781449369880/">Link</a></li>
            <li>A course in Machine Learning <a href="http://ciml.info">Link</a></li>
        </ul>
        <hr />

        <h3>Academic Integrity</h3>
        Any plagiarism, copying, allowing copying, unpermitted aid will lead to 'zero' in the assignment/exam/project.
        <hr />

        <h3>Past Courses</h3>
        <ul>
            <li><a href="https://www.niser.ac.in/~smishra/teach/cs460/23cs460/">2023 CS460/660 - Machine Learning</a>
            </li>
            <li><a href="https://www.niser.ac.in/~smishra/teach/cs460/2021/">2021 CS460/660 - Machine Learning</a></li>
            <li><a href="https://www.niser.ac.in/~smishra/teach/cs460/2020/">2020 CS460/660 - Machine Learning</a></li>
        </ul>
        <br> <br>
        <div class="navbar">
            <a href="https://www.niser.ac.in/~smishra/index.html">Home</a>
            <a href="https://www.niser.ac.in/~smishra/people.html">People</a>
            <a href="https://www.niser.ac.in/~smishra/research.html">Research</a>
            <a href="https://www.niser.ac.in/~smishra/teaching.html" class="active">Teaching</a>
            <a href="https://www.niser.ac.in/~smishra/events.html">Events</a>
        </div>
    </div>
</body>

</html>